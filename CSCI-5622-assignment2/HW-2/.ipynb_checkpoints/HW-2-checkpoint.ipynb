{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework - 2\n",
    "***\n",
    "**Name**: Bhalchandra Naik\n",
    "***\n",
    "\n",
    "This assignment is due on Canvas by **5pm on Friday October 5th**. Submit only this Jupyter notebook to Canvas.  Do not compress it using tar, rar, zip, etc. Your solutions to analysis questions should be done in Markdown directly below the associated question.  Remember that you are encouraged to discuss the problems with your classmates and instructors, but **you must write all code and solutions on your own**, and list any people or sources consulted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting - Extra Credit [5-points]\n",
    "***\n",
    "\n",
    "In this problem, we slightly modify the AdaBoost algorithm to better explore some properties of the algorithm. Specifically, we no longer normalize the weights on the training examples after each iteration. The modified algorithm, which is set to run for $T$ iterations, is shown in Algorithm I.\n",
    "\n",
    "Note that in the modified version, the weights associated with the training examples are no longer guaranteed to sum to one after each iteration (and therefore can not be viewed as a \"distribution\"), but the algorithm is still valid. Let us denote the sum of weights at the start of iteration $t$ by $Z_t = \\sum_{i=1}^{n}w_i^{(t)}$. At the start of the first iteration of boosting, $Z_1 = n$. Let us now investigate the behavior of $Z_t$, as a function of t\n",
    "\n",
    "![image](fig-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A:** At the $t^{th}$ iteration, we found a weak classifier that achieves a weighted training error $\\epsilon_t$. Show that the choice, $\\alpha_t = \\frac{1}{2}\\log\\frac{1 - \\epsilon_t}{\\epsilon_t}$ is the optimal in the sense that it minimizes $Z_{t+1}$\n",
    "\n",
    "*Hint: Look at $Z_{t+1}$ as function of $\\alpha$ and find the value of $\\alpha$ for which the function achieves the minimum. You may also find the following notational shorthand useful:\n",
    "\n",
    "$$W_t = \\sum_{i=1}^{n}w_i^{(t)}(1 - \\delta(y_i, h_t(x_i)))$$\n",
    "$$W_c = \\sum_{i=1}^{n}w_i^{(t)}(\\delta(y_i, h_t(x_i)))$$\n",
    "\n",
    "where $W_c$ is the total weight of the points classified correctly by $h_t$ and $W_t$ is the total weight of the misclassified points. $\\delta(y, h_t(x)) = 1$ whenever the label predicted by $h_t$ is correct and zero otherwise. The weights here are those available at the start of iteration $t$\n",
    "\n",
    "__Solution__:\n",
    "\n",
    "> Let us first express the quantity $Z_{t+1}$ in terms of $\\alpha_t$. We know that:\n",
    "$$Z^{t+1} = \\sum_{i=1}^{n}w_i^{(t+1)}$$\n",
    "> Now we know that $w_i^{t+1} = w_i^{(t)}e^{-y_ih_t(x_i)\\alpha_t}$. On substituting this value in the above equation we get:\n",
    "$$Z^{t+1} = \\sum_{i=1}^{n}w_i^{(t)}e^{-y_ih_t(x_i)\\alpha_t}$$\n",
    "> Now we need to split this summation in terms of $\\delta(y_i, h_t(x_i))$ for classified points and $(1-\\delta(y_i, h_t(x_i)))$\n",
    "for misclassified points. Therefore we get : \n",
    "$$Z^{t+1} = \\sum_{i=1}^{n}w_i^{(t)}e^{-y_ih_t(x_i)\\alpha_t}(1-\\delta(y_i, h_t(x_i))) + \\sum_{i=1}^{n}w_i^{(t)}e^{-y_ih_t(x_i)\\alpha_t}\\delta(y_i, h_t(x_i))$$\n",
    "> Now for misclassified points the $y_ih_t(x_i) = -1$ and for correctly classified points it becomes $y_ih_t(x_i) = 1$. Thus substituting these values above we get:\n",
    "$$Z^{t+1} = \\sum_{i=1}^{n}w_i^{(t)}e^{\\alpha_t}(1-\\delta(y_i, h_t(x_i))) + \\sum_{i=1}^{n}w_i^{(t)}e^{-\\alpha_t}\\delta(y_i, h_t(x_i))$$\n",
    "> Now, $\\epsilon_t = \\frac{1}{Z_t}\\sum_{i=1}^{n}w_i^{(t)}(1-\\delta(y_i, h_t(x_i)))$ and $(1-\\epsilon_t) = \\frac{1}{Z_t}\\sum_{i=1}^{n}w_i^{(t)}\\delta(y_i, h_t(x_i))$.  Thus on substituting in the relation above we get:\n",
    "$$Z^{t+1} = e^{\\alpha_t}\\epsilon_tZ_t + e^{-\\alpha_t}(1-\\epsilon_t)Z_t$$\n",
    "> Now, we expressed $Z_{t+1}$ as a function of $\\alpha_t$ diffrentiating on both sides with $\\alpha_t$ we get,\n",
    "$$\\frac{\\delta Z^{t+1}}{\\delta\\alpha_t} = \\alpha_te^{\\alpha_t}\\epsilon_tZ_t -\\alpha_t e^{-\\alpha_t}(1-\\epsilon_t)Z_t$$\n",
    "> For the value of $\\alpha_t$ that minimizes the value of $Z_{t+1}$, the value of the above diffrential $\\frac{\\delta Z^{t+1}}{\\delta\\alpha_t}$ shall be $0$,\n",
    "$$\\alpha_te^{\\alpha_t}\\epsilon_tZ_t -\\alpha_t e^{-\\alpha_t}(1-\\epsilon_t)Z_t = 0$$\n",
    "> Eliminating common terms like $Z_t$ and $\\alpha_t$ from coefficients we get,\n",
    "$$e^{\\alpha_t}\\epsilon_t -e^{-\\alpha_t}(1-\\epsilon_t) = 0$$\n",
    "$$e^{\\alpha_t}\\epsilon_t  = e^{-\\alpha_t}(1-\\epsilon_t)$$\n",
    "$$e^{2\\alpha_t} = \\frac{1-\\epsilon_t}{\\epsilon_t}$$\n",
    "> Taking $log_e$ on both sides we get:\n",
    "$$2\\alpha_t = log(\\frac{1-\\epsilon_t}{\\epsilon_t})$$\n",
    "$$\\boxed{\\alpha_t = \\frac{1}{2}log(\\frac{1-\\epsilon_t}{\\epsilon_t})}$$\n",
    "Thus proved that the optimal value that minimizes $Z_{t+1}$ is $\\alpha_t = \\frac{1}{2}log(\\frac{1-\\epsilon_t}{\\epsilon_t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B:** Show that the sum of weights $Z_t$ is monotonically decreasing as a function of $t$.\n",
    "\n",
    "__Solution:__\n",
    "> Let us first describe the the quantity $Z_{t+1}$ in terms of the value $\\epsilon_t$. We Know that $w_i^{(t+1)} = w_i^{(t)}e^{-y_ih_t(x_i)\\alpha_t}$. Thus,\n",
    "$$Z^{t+1} = \\sum_{i=1}^{n}w_i^{(t+1)} = \\sum_{i=1}^{n}w_i^{(t)}e^{-y_ih_t(x_i)\\alpha_t}$$\n",
    "> Now we need to split this summation in terms of $\\delta(y_i, h_t(x_i))$ for classified points and $(1-\\delta(y_i, h_t(x_i)))$\n",
    "for misclassified points. Therefore we get : \n",
    "$$Z^{t+1} = \\sum_{i=1}^{n}w_i^{(t)}e^{-y_ih_t(x_i)\\alpha_t}(1-\\delta(y_i, h_t(x_i))) + \\sum_{i=1}^{n}w_i^{(t)}e^{-y_ih_t(x_i)\\alpha_t}\\delta(y_i, h_t(x_i))$$\n",
    "> Now for misclassified points the $y_ih_t(x_i) = -1$ and for correctly classified points it becomes $y_ih_t(x_i) = 1$. Thus substituting these values above we get:\n",
    "$$Z^{t+1} = \\sum_{i=1}^{n}w_i^{(t)}e^{\\alpha_t}(1-\\delta(y_i, h_t(x_i))) + \\sum_{i=1}^{n}w_i^{(t)}e^{-\\alpha_t}\\delta(y_i, h_t(x_i))$$\n",
    ">Lets simplifying the above expression. Put $W_t = \\sum_{i=1}^{n}w_i^{(t)}(1 - \\delta(y_i, h_t(x_i)))$ and $W_c = \\sum_{i=1}^{n}w_i^{(t)}(\\delta(y_i, h_t(x_i)))$, we get,\n",
    "$$Z^{t+1} = e^{\\alpha_t}W_t^t + e^{-\\alpha_t}W_c^t$$\n",
    "> We know that $Z^{t} = W_t^t+W_c^t$, on subtracting the above expression with this one we get,\n",
    "$$Z^{t+1} -  Z^{t}= e^{\\alpha_t}W_t^t + e^{-\\alpha_t}W_c^t - W_t^t - W_c^t$$\n",
    "$$Z^{t+1} -  Z^{t}= (e^{\\alpha_t} - 1)W_t^t + (e^{-\\alpha_t}-1)W_c^t$$\n",
    "$$\\frac{Z^{t+1}}{Z^{t}} - 1 = (e^{\\alpha_t} - 1)\\frac{W_t^t}{Z^{t}} + (e^{-\\alpha_t}-1)\\frac{W_c^t}{Z^{t}}$$\n",
    "> Now, the subsitute the value of $\\alpha_t = \\frac{1}{2}log\\frac{1-\\epsilon_t}{\\epsilon_t}$ and simplify the quantities of $\\frac{W_t^t}{Z^{t}} = \\epsilon_t$ and $\\frac{W_c^t}{Z^{t}} = 1-\\epsilon_t$:\n",
    "$$\\frac{Z^{t+1}}{Z^{t}} - 1 = (e^{\\frac{1}{2}log\\frac{1-\\epsilon_t}{\\epsilon_t}} - 1)\\epsilon_t + (e^{-\\frac{1}{2}log\\frac{1-\\epsilon_t}{\\epsilon_t}}-1)(1-\\epsilon_t)$$\n",
    "> On simplification we get :\n",
    "$$\\frac{Z^{t+1}}{Z^{t}} - 1 = \\epsilon_t^{\\frac{1}{2}}(1-\\epsilon_t)^{\\frac{1}{2}} - \\epsilon_t + \\epsilon_t^{\\frac{1}{2}}(1-\\epsilon_t)^{\\frac{1}{2}} -1+ \\epsilon_t$$\n",
    "$$\\frac{Z^{t+1}}{Z^{t}} = 2\\sqrt{\\epsilon_t(1-\\epsilon_t)}$$\n",
    "$$Z^{t+1} = 2\\sqrt{\\epsilon_t(1-\\epsilon_t)}Z^{t}$$\n",
    "> Now put $f(\\epsilon_t) = 2\\sqrt{\\epsilon_t(1-\\epsilon_t)}$ then,\n",
    "$$Z^{t+1} = f(\\epsilon_t)Z^{t}$$\n",
    "> Now let us analyse the function $f(\\epsilon_t)$. On diffrentiating we get,\n",
    "$$\\frac{\\delta f(\\epsilon_t)}{\\delta\\epsilon_t} = 2 \\times \\frac{1}{2}\\frac{1}{\\sqrt{\\epsilon_t(1-\\epsilon_t)}}\\times (1-2\\epsilon_t) = \\frac{(1-2\\epsilon_t)}{\\sqrt{\\epsilon_t(1-\\epsilon_t)}}$$\n",
    ">The maxima of this function occurs at the point when $f(\\epsilon_t) = 0$. Therefore,\n",
    "$$\\frac{(1-2\\epsilon_t)}{\\sqrt{\\epsilon_t(1-\\epsilon_t)}} = 0$$\n",
    "$$\\therefore (1-2\\epsilon_t) = 0$$\n",
    "$$\\therefore \\epsilon_t = \\frac{1}{2}$$\n",
    ">For the value of $\\frac{1}{2}$ the value of $f(\\epsilon) = 2\\sqrt{\\frac{1}{2}(1-\\frac{1}{2})} = 1$. This means that the maximum value the function $f(\\epsilon_t)$ is $1$ i.e $f(\\epsilon_t) \\leq 1$. Hence, \n",
    "$$\\boxed{Z^{t+1} \\leq Z^{t}}$$\n",
    "> The above equation implies that $Z^{t+1}$ is a monotonously decreasing function of as for any $t$  the value $Z_{t+1} \\leq Z_{t}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "***\n",
    "Please do not change this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.base import clone\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreesAndEights:\n",
    "    \"\"\"\n",
    "    Class to store MNIST data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, location):\n",
    "\n",
    "        import pickle, gzip\n",
    "\n",
    "        # Load the dataset\n",
    "        f = gzip.open(location, 'rb')\n",
    "\n",
    "        # Split the data set \n",
    "#         X_train, y_train, X_valid, y_valid = pickle.load(f)\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "    \n",
    "        X_train, y_train = train_set\n",
    "        X_valid, y_valid = valid_set\n",
    "\n",
    "        # Extract only 3's and 8's for training set \n",
    "        self.X_train = X_train[np.logical_or( y_train==3, y_train == 8), :]\n",
    "        self.y_train = y_train[np.logical_or( y_train==3, y_train == 8)]\n",
    "        self.y_train = np.array([1 if y == 8 else -1 for y in self.y_train])\n",
    "        \n",
    "        # Shuffle the training data \n",
    "        shuff = np.arange(self.X_train.shape[0])\n",
    "        np.random.shuffle(shuff)\n",
    "        self.X_train = self.X_train[shuff,:]\n",
    "        self.y_train = self.y_train[shuff]\n",
    "\n",
    "        # Extract only 3's and 8's for validation set \n",
    "        self.X_valid = X_valid[np.logical_or( y_valid==3, y_valid == 8), :]\n",
    "        self.y_valid = y_valid[np.logical_or( y_valid==3, y_valid == 8)]\n",
    "        self.y_valid = np.array([1 if y == 8 else -1 for y in self.y_valid])\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ThreesAndEights(\"data/mnist.pklz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore this data and get comfortable with it before proceeding further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "Bootstrap aggregating, also called bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach.\n",
    "\n",
    "Given a standard training set $D$ of size n, bagging generates $N$ new training sets $D_i$, roughly each of size n * ratio, by sampling from $D$ uniformly and with replacement. By sampling with replacement, some observations may be repeated in each $D_i$ The $N$ models are fitted using the above $N$ bootstraped samples and combined by averaging the output (for regression) or voting (for classification). \n",
    "\n",
    "-Source [Wiki](https://en.wikipedia.org/wiki/Bootstrap_aggregating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Bagging [5-points]\n",
    "***\n",
    "\n",
    "We've given you a skeleton of the class `BaggingClassifier` below which will train a classifier based on the decision trees as implemented by sklearn. Your tasks are as follows, please approach step by step to understand the code flow:\n",
    "* Implement `bootstrap` method which takes in two parameters (`X_train, y_train`) and returns a bootstrapped training set ($D_i$)\n",
    "* Implement `fit` method which takes in two parameters (`X_train, y_train`) and trains `N` number of base models on different bootstrap samples. You should call `bootstrap` method to get bootstrapped training data for each of your base model\n",
    "* Implement `voting` method which takes the predictions from learner trained on bootstrapped data points `y_hats` and returns final prediction as per majority rule. In case of ties, return either of the class randomly.\n",
    "* Implement `predict` method which takes in multiple data points and returns final prediction for each one of those. Please use the `voting` method to reach consensus on final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import clone\n",
    "\n",
    "class BaggingClassifier:\n",
    "    def __init__(self, ratio = 0.20, N = 20, base=DecisionTreeClassifier(max_depth=4)):\n",
    "        \"\"\"\n",
    "        Create a new BaggingClassifier\n",
    "        \n",
    "        Args:\n",
    "            base (BaseEstimator, optional): Sklearn implementation of decision tree\n",
    "            ratio: ratio of number of data points in subsampled data to the actual training data\n",
    "            N: number of base estimator in the ensemble\n",
    "        \n",
    "        Attributes:\n",
    "            base (estimator): Sklearn implementation of decision tree\n",
    "            N: Number of decision trees\n",
    "            learners: List of models trained on bootstrapped data sample\n",
    "        \"\"\"\n",
    "        \n",
    "        assert ratio <= 1.0, \"Cannot have ratio greater than one\"\n",
    "        self.base = base\n",
    "        self.ratio = ratio\n",
    "        self.N = N\n",
    "        self.learners = []\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train Bagging Ensemble Classifier on data\n",
    "        \n",
    "        Args:\n",
    "            X_train (ndarray): [n_samples x n_features] ndarray of training data   \n",
    "            y_train (ndarray): [n_samples] ndarray of data \n",
    "        \"\"\"\n",
    "        #TODO: Implement functionality to fit models on the bootstrapped samples\n",
    "        # cloning sklearn models:\n",
    "        # from sklearn.base import clone\n",
    "        # h = clone(self.base)\n",
    "        for i in range(self.N):\n",
    "            b_X, b_y = self.boostrap(X_train, y_train)\n",
    "            model_clone = clone(self.base)\n",
    "            model_clone.fit(b_X, b_y)\n",
    "            self.learners.append(model_clone)\n",
    "        \n",
    "        \n",
    "    def boostrap(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n (int): total size of the training data\n",
    "            X_train (ndarray): [n_samples x n_features] ndarray of training data   \n",
    "            y_train (ndarray): [n_samples] ndarray of data \n",
    "        \"\"\"\n",
    "        masks = np.random.choice(list(range(0, len(y_train))), size = int(len(y_train)*self.ratio))\n",
    "        b_X, b_y = X_train[masks], y_train[masks]\n",
    "        return b_X, b_y\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        BaggingClassifier prediction for data points in X\n",
    "        \n",
    "        Args:\n",
    "            X (ndarray): [n_samples x n_features] ndarray of data \n",
    "            \n",
    "        Returns:\n",
    "            yhat (ndarray): [n_samples] ndarray of predicted labels {-1,1}\n",
    "        \"\"\"\n",
    "        \n",
    "        #TODO: Using the individual classifiers trained predict the final prediction using voting mechanism\n",
    "        y_hat = []\n",
    "        for xx in X:\n",
    "            y_hats = []\n",
    "            for learner in self.learners:\n",
    "                y_hats.append(learner.predict([xx])[0])\n",
    "            y_hat.append(self.voting(y_hats))\n",
    "        return y_hat\n",
    "    \n",
    "    def voting(self, y_hats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            y_hats (ndarray): [N] ndarray of data\n",
    "        Returns:\n",
    "            y_final : int, final prediction of the \n",
    "        \"\"\"\n",
    "        #TODO: Implement majority voting scheme and incase of ties return random label\n",
    "        classes, counts = np.unique(y_hats, return_counts = True)\n",
    "        return classes[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaggingClassifier for Handwritten Digit Recognition [5-points]\n",
    "***\n",
    "\n",
    "After you've successfully completed `BaggingClassifier` find the optimal values of `ratio`, `N` and `depth` using k-fold cross validation. You are allowed to use sklearn library to split your training data in folds. Use the data from `ThreesAndEights` class initialized variable `data`. \n",
    "\n",
    "Justify why those values are optimal.\n",
    "\n",
    "Report accuracy on the validation data using the optimal parameter values.\n",
    "\n",
    "__Solution:__\n",
    "> The optimal values the bagging classifier using decision trees are achieved at `ratio = 0.275`, `N = 25` and `depth = 18`. As we see in the graphs below we shall see that the maxima of the accuracy is at the above values after which the accuracy shows a decreasing trend due to increasing overfitting as decision trees have a tendency to overfit the data, due to excessive effort for seperating the data well in training which introduces errors in testing. The accuracy for these values is found to be approximately, $97\\%$. The values above may vary slightly due to randomization in the algorithm of selecting data and selection of splitting vector or hyperplane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed the accuracy for ratio :  0.05\n",
      "Computed the accuracy for ratio :  0.07500000000000001\n",
      "Computed the accuracy for ratio :  0.10000000000000002\n",
      "Computed the accuracy for ratio :  0.12500000000000003\n",
      "Computed the accuracy for ratio :  0.15000000000000002\n",
      "Computed the accuracy for ratio :  0.17500000000000004\n",
      "Computed the accuracy for ratio :  0.20000000000000007\n",
      "Computed the accuracy for ratio :  0.22500000000000003\n",
      "Computed the accuracy for ratio :  0.25000000000000006\n",
      "Computed the accuracy for ratio :  0.2750000000000001\n",
      "Computed the accuracy for ratio :  0.3000000000000001\n",
      "Computed the accuracy for ratio :  0.32500000000000007\n",
      "Computed the accuracy for ratio :  0.3500000000000001\n",
      "Computed the accuracy for ratio :  0.3750000000000001\n",
      "Computed the accuracy for ratio :  0.4000000000000001\n",
      "Computed the accuracy for ratio :  0.4250000000000001\n",
      "Computed the accuracy for ratio :  0.4500000000000001\n",
      "Computed the accuracy for ratio :  0.47500000000000014\n",
      "Computed the accuracy for ratio :  0.5000000000000002\n",
      "Computed the accuracy for ratio :  0.5250000000000001\n",
      "Computed the accuracy for ratio :  0.5500000000000003\n",
      "Computed the accuracy for ratio :  0.5750000000000002\n",
      "Computed the accuracy for ratio :  0.6000000000000002\n",
      "Computed the accuracy for ratio :  0.6250000000000002\n",
      "Computed the accuracy for ratio :  0.6500000000000002\n",
      "Computed the accuracy for ratio :  0.6750000000000003\n",
      "Computed the accuracy for ratio :  0.7000000000000003\n",
      "Computed the accuracy for ratio :  0.7250000000000003\n",
      "The optimal value of Ratio for the classifier is :  0.2750000000000001\n",
      "Computed the accuracy for N :  15\n",
      "Computed the accuracy for N :  17\n",
      "Computed the accuracy for N :  19\n",
      "Computed the accuracy for N :  21\n",
      "Computed the accuracy for N :  23\n",
      "Computed the accuracy for N :  25\n",
      "Computed the accuracy for N :  27\n",
      "Computed the accuracy for N :  29\n",
      "Computed the accuracy for N :  31\n",
      "Computed the accuracy for N :  33\n",
      "The optimal value of N for the classifier is :  25\n",
      "Computed the accuracy for depth :  3\n",
      "Computed the accuracy for depth :  6\n",
      "Computed the accuracy for depth :  9\n",
      "Computed the accuracy for depth :  12\n",
      "Computed the accuracy for depth :  15\n",
      "Computed the accuracy for depth :  18\n",
      "Computed the accuracy for depth :  21\n",
      "Computed the accuracy for depth :  24\n",
      "Computed the accuracy for depth :  27\n",
      "Computed the accuracy for depth :  30\n",
      "Computed the accuracy for depth :  33\n",
      "Computed the accuracy for depth :  36\n",
      "Computed the accuracy for depth :  39\n",
      "Computed the accuracy for depth :  42\n",
      "Computed the accuracy for depth :  45\n",
      "Computed the accuracy for depth :  48\n",
      "The optimal value of depth for the classifier is :  18\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xl8lOW58PHflZ0sLFmBBAhrICCKRlRoJaJEbN21rXpq1Z7qe1ptT/fq2/PaHno8eqpdTnvsYk/dWqu11LaAuFAEtSJIEJJAIBDClgUSCJkASch2vX/MMzjGCZnAbEmu7+czn8zcz3bNMOTKcz/Xc9+iqhhjjDGhFBXuAIwxxgw9lnyMMcaEnCUfY4wxIWfJxxhjTMhZ8jHGGBNylnyMMcaEnCUfY4wxIWfJxxhjTMhZ8jHGGBNyMeEOIFKlp6drbm5uuMMwxpgBY9OmTYdVNcOfdS359CI3N5fi4uJwh2GMMQOGiOzzd92gdruJyGIRqRCRShG538fyCSKyWkRKRWStiOR4LesSkS3OY5lXu4jIQyKyU0S2i8hXvNp/5hyrVETO99rmDhHZ5TzuCOZ7NsYY07egnfmISDTwOLAIqAY2isgyVS33Wu0x4FlVfUZEFgIPA7c7y1pV9Twfu74TGAdMV9VuEcl02q8CpjqPi4BfAheJSCrwPaAAUGCTE8fRAL5dY4wx/RDMM5+5QKWqVqlqO/ACcF2PdfKB1c7zNT6W+/JFYImqdgOoar3Tfh3uRKaquh4YKSJjgCuBVara6CScVcDis3ljxhhjzk4wk082cMDrdbXT5q0EuMl5fgOQIiJpzusEESkWkfUicr3XNpOBzzjLXhGRqX0cz584ABCRe5z9Fjc0NPj3Lo0xxvRbMJOP+GjrOXnQN4EFIrIZWADUAJ3OsvGqWgDcBvxURCY77fFAm7PsN8CTfRzPnzjcjapPqGqBqhZkZPhVsGGMMeYMBDP5VOO+NuORA9R6r6Cqtap6o6rOAb7rtLk8y5yfVcBaYI7Xfv/sPP8LMLuP4/UZhzHGmNAKZvLZCEwVkYkiEgfcAizzXkFE0kXEE8MDOGcxIjJKROI96wDzAU+hwl+Bhc7zBcBO5/ky4HNO1dvFgEtV64DXgCJnn6OAIqfNGGNMmASt2k1VO0XkPty/6KOBJ1V1m4gsAYpVdRlQCDwsIgq8BdzrbD4D+LWIdONOkI94Vck9AjwnIl8DjgNfcNpXAp8AKoEW4C4njkYR+QHuZAjuYoXGYL1vYyLd27sayBqewLSslHCHYoYwUfV5+WPIKygoULvJ1Aw2qsp5S1Yxc+xw/nD3xeEOxwwyIrLJuR7fJxvbzZghZH9jC67WDjbubeT4yc6+NzAmSCz5GDOElFa7AOjoUtZVHg5zNGYos+RjzBCytcZFXHQUSXHRrN1p97KZ8LGBRY0ZQkqrXUwfk8Lo4Qm8WdGAqiLi61Y4Y4LLznyMGSK6u5WttS7OyR5BYV4mNU2tVNYfD3dYZoiy5GPMELGvsYVjbZ1O8nGP4LG2wrreTHhY8jFmiCircRcbnJMzgrEjhzEtK5m1O+v72MqY4LDkY8wQUVbdRFxM1KmbSwvzMtm45ygnrOTahIElH2OGiNJqFzPGDCc22v3fvnBaBu1d3azbfSTMkZmhyJKPMUNAd7eyrbaZc7KHn2oryE11l1xXWNebCT1LPsYMAXuOnOD4yU5mZ4881RYXE8W8KemsdUqujQklSz7GDAFbnWKDWdkjPtRemJdBTVMruxus5NqEliUfY4aA0moX8TFRTM1K/lB7YV4mYCXXJvQs+RgzBJTVuMgf+0GxgUf2yGFMzUy25GNCzpKPMYNcd7eyrcY9soEvhXkZvLen0UquTUgFNfmIyGIRqRCRShG538fyCSKyWkRKRWStiOR4LesSkS3OY5lX+9Missdr2XlO+7e82rY626c6y/aKSJmzzCbpMUNK1eETnGjvOk3yyaS9q5t3reTahFDQBhYVkWjgcWARUA1sFJFlXjOSAjwGPKuqz4jIQuBh4HZnWauqntfL7r+lqku9G1T1UeBR59jXAF/rMWPpZapqY8ibIaespglwj2zgS0HuKBLjolm7s54r8rNCGZoZwoJ55jMXqFTVKlVtB14AruuxTj6w2nm+xsfyM3Ur8HyA9mXMgFZW3UxCbBRTMpJ9Lo+PiWbeZCu5NqEVzOSTDRzwel3ttHkrAW5ynt8ApIhImvM6QUSKRWS9iFzfY7uHnK66n4hIvPcCEUkEFgN/9mpW4HUR2SQi95zFezJmwCmraSJ/zHBionv/716Yl0H10VZ2N5wIYWRmKAtm8vE1SUjPP6u+CSwQkc3AAqAG8Fz1HO/MBX4b8FMRmey0PwBMBy4EUoHv9NjnNcA7Pbrc5qvq+cBVwL0icqnPgEXucRJecUODVf+Yga+rW9la08zsnJGnXe+DUa5ttAMTGsFMPtXAOK/XOUCt9wqqWquqN6rqHOC7TpvLs8z5WQWsBeY4r+vU7STwFO7uPW+30KPLzWtf9cBffGzjWe8JVS1Q1YKMjIx+v2FjIk1Vw3FaO7o+cnNpTzmjEpmSmcybNrupCZFgJp+NwFQRmSgicbiTwjLvFUQkXUQ8MTwAPOm0j/J0p4lIOjAfKHdej3F+CnA9sNVrfyNwn0H9zastSURSPM+BIu9tjBnMSqvdIxvM7qXYwFvhtAw2VDXS0m4l1yb4gpZ8VLUTuA94DdgOvKiq20RkiYhc66xWCFSIyE4gC3jIaZ8BFItICe5ChEe8quSeE5EyoAxIB/7D67A3AK+rqnfHdRbwD2df7wEvq+qrAX67xkSkshoXw2KjmdxLsYE3K7k2oRS0UmsAVV0JrOzR9qDX86XAUh/brQPO6WWfC09zvKeBp3u0VQHn9iNsYwaNshoXM8cOJzrK1yXYD7twolNyXdHA5TOs5NoEl41wYMwg1dnVTXltc6/39/TkLrlOY+3Oeiu5NkFnyceYQWp3wwlaO3of2cCXBXmZHGhspeqwlVyb4LLkY8wgVVbjf7GBR+E0T8m1Vb2Z4LLkY8wgVVbdRGJcNBPT+y428BiXmsjkjCS738cEnSUfYwapshoXs8aO8KvYwFthXiYb9jTS2t4VpMiMseRjzKDU2dVNeV1znzeX+lKYl0F7ZzfvVtk4vCZ4LPkYMwhVNhynraO7X9d7POZOTGVYbLRd9zFBZcnHmEHIM7LBmZz5nCq5tlGuTRBZ8jFmECqrdpEUF82k9KQz2r5weib7G1vYYyXXJkgs+RgzCJXVuJiZPYKofhYbeFjJtQk2Sz7GDDIdTrHB7DPocvM4VXJto1ybILHkY8wgs+vQcdo7u/0eVqc3hXmZrK86YiXXJigs+RgzyJTVNAH0a1gdXzwl1+urbJRrE3iWfIwZZMpqXKTEx5CbdmbFBh4flFzbaAcm8Cz5GDPIlFW7mJk9/IyLDTw8JddrrOTaBIElH2MGkfbObrYfPMbsnJEB2V9hXoaVXJugCGryEZHFIlIhIpUicr+P5RNEZLWIlIrIWhHJ8VrWJSJbnMcyr/anRWSP17LznPZCEXF5tT/otc1p4zBmsNh56Bjtnd1ndHOpL4V5mYCVXJvAC9pMpiISDTwOLAKqgY0issxrOmyAx4BnVfUZEVkIPAzc7ixrVdXzetn9t5xZUHt6W1WvPoM4jBkUtnqmUQhQ8hmXmsgkp+T68x+bGJB9GgPBPfOZC1SqapWqtgMvANf1WCcfWO08X+NjeajiMGZQKK1xkZIQw4S0xIDts3CalVybwAtm8skGDni9rnbavJUANznPbwBSRCTNeZ0gIsUisl5Eru+x3UNOV91PRCTeq/0SESkRkVdEZGY/4gBARO5xjlnc0GDdDGbg2Vrj4pzsEYicXbGBNyu5NsEQzOTj69vfs2Tmm8ACEdkMLABqgE5n2XhVLQBuA34qIpOd9geA6cCFQCrwHaf9fWCCqp4L/Bz4az/icDeqPqGqBapakJGR0df7MyainOzsYntd81nf39OTlVybYAhm8qkGxnm9zgFqvVdQ1VpVvVFV5wDfddpcnmXOzypgLTDHeV2nbieBp3B3q6Gqzap63Hm+EogVkXR/4jBmMNh58DgdXXrWIxv0lBAbzSWT02yoHRNQwUw+G4GpIjJRROKAW4Bl3iuISLqIeGJ4AHjSaR/l6U5zEsh8oNx5Pcb5KcD1wFbn9WinDRGZ67y3I/7EYcxgUHaq2CAwZdbeCvMy2HfESq5N4AQt+ahqJ3Af8BqwHXhRVbeJyBIRudZZrRCoEJGdQBbwkNM+AygWkRLchQiPeFWnPSciZUAZkA78h9N+M7DV2eZnwC3OGZLPOIL1vo0Jl7KaJkYMi2Vc6rCA77twmqfk2rreTGCI3bnsW0FBgRYXF4c7DGP8dvXP32bksDh+/4WLgrL/hY+tZVxqIs98fm5Q9m8GPhHZ5Fyr75ONcGDMIHCys4uKg8cCdnOpLwvyMlhfdYS2Diu5NmfPko8xg0DFwWN0dCmzA1xs4K0wL5OTnd28ayXXJgAs+RgzCJRWu4sNAl1m7e2iiakkxEbxpg21YwLAko8xg8DWGhcjE2PJGRX4YgOPhNhoLpmUZkUHJiAs+RgzCJRWB35kA18K8zLZe6SFvVZybc6SJR9jBri2ji52HjoW1C43j8I898gfdvZjzpYlH2MGuB0Hj9HZrSFJPhPSkpiYnmSjHZizZsnHmAGurLoJIODD6vRmwbQM3t1tJdfm7FjyMYNeV7fS3NYR7jCCpqzGRWpSHNkjg1ds4K0wL4OTNsq1OUuWfMyg98u1lVz6wzW0tHf2vfIAVFrtYlYIig08Lp6URnxMlM1uas6KJR8zqKkqf9pUTVNLB2/tPBzucAKuraOLXfXHAzZzqT88o1y/add9zFmw5GMGta01zew70gLAqvJDYY4m8Mrrmunq1qAOq+NL4bQM9hw+wb4jVnJtzowlHzOoLS+tJSZKWDg9k9U7DtHZ1R3ukAJqq2cahRAVG3gU5nlGubazH3NmLPmYQau7W3m5tI5Lp2XwqQtyaGrpYOPeo+EOK6BKq12kJcUxZkRCSI+bm55Eblqi3e9jzpglHzNobT5wlJqmVq45dwyXTssgLiZq0HW9ba1xcU5O6IoNvBXmZfKujXJtzlBQk4+ILBaRChGpFJH7fSyfICKrRaRURNaKSI7Xsi4R2eI8lnm1Py0ie7yWnee0/5Ozn1IRWSci53pts1dEypz1bZKeIWJ5SR1xMVFcMSOLpPgYPj4lndfLDzJY5rBqbQ/dyAa+LMjLoK2jmw17GsNyfDOwBS35iEg08DhwFZAP3Coi+T1Wewx4VlVnA0uAh72Wtarqec7j2h7bfctr2RanbQ+wwNnXD4AnemxzmbO+XxMdmYGtq1t5uayOhXmZpCTEArAoP4vqo61srzsW5ugCo7yumW4N7kjWp3PJqZJr63oz/RfMM5+5QKWqVqlqO/ACcF2PdfKB1c7zNT6W+01V16mqp0N/PZBzuvXN4LZhzxEajp3k6nPHnGq7fEYWIvB6+cEwRhY4oR7ZoKeE2GgunpRmUyyYMxLM5JMNHPB6Xe20eSsBbnKe3wCkiEia8zpBRIpFZL2IXN9ju4ec7rWfiEi8j2P/M/CK12sFXheRTSJyzxm9GzOgLC+pIzEumoXTM0+1ZaTEc8H4UYPmuk9ZTTPpyfGMHh7aYgNvhXkZVB0+wX6nnN0YfwUz+fi6Atqzs/2bwAIR2QwsAGoAz23o450ustuAn4rIZKf9AWA6cCGQCnznQwcVuQx38vFun6+q5+PuArxXRC71GbDIPU7CK25osL/mBqqOrm5e3VrHFTOySIyL+dCyoplZbKttpvrowP9lWVbTxOwwFRt4nCq53mldb6Z/gpl8qoFxXq9zgFrvFVS1VlVvVNU5wHedNpdnmfOzClgLzHFe16nbSeAp3N17AIjIbOB/getU9Yj3cZyf9cBfvLfpEc8TqlqgqgUZGRln8dZNOL1TeZijLR1cPXvMR5Ytyh8NDPwbTlvaO6msPx7ym0t7mpiexIS0RLvfx/RbMJPPRmCqiEwUkTjgFmCZ9woiki4inhgeAJ502kd5utNEJB2YD5Q7r8c4PwW4HtjqvB4PvATcrqo7vY6RJCIpnudAkWcbMzitKK0jJSGGBXkf/QNiYnoSUzOTB3zyKa91FxuEclid3hROy2Dd7sNWcm36JWjJR1U7gfuA14DtwIuquk1EloiIp3qtEKgQkZ1AFvCQ0z4DKBaREtyFCI+oarmz7DkRKQPKgHTgP5z2B4E04Bc9SqqzgH84+3oPeFlVXw3OuzbhdrKzi9e2HqQofzTxMdE+1ymamcWGPY00tbSHOLrAKa12j2wQrmIDb4V5mbR1dPOelVybfojpe5Uzp6orgZU92h70er4UWOpju3XAOb3sc2Ev7V8AvuCjvQo496NbmMHozYoGjp3s5JpzP9rl5rEofzSPr9nNGzvqufH8gVkUubXGRWZKPFlhLDbwuHhSGnHOKNeXTrPuauMfG+HADCorSusYlRjL/Cnpva4zO3sEWcPjeX3bwO16K61xhe3+np6GxblLrq3owPSHJR8zaLS2d/H37YdYPGsMsdG9f7WjooRF+Vm8tathQF6nOHGyk90NxyOiy82jcFoGVQ0nONA48KsITWhY8jGDxhs76mlp7zptl5tHUf5oWtq7eKdy4M3xs622GQ3jyAa+FDrFHTbagfGXJR8zaCwvqSUjJZ6LJqb1ue7Fk9JIiY8ZkF1vZc40CpGUfCamJzE+1Uqujf8s+ZhB4VhbB29U1PPJc8YQHdX3TZdxMVEUOnP8dHUPrIFGy6qbGD08gcwIKDbwEBEK8zJYt9tGuTb+8Sv5iMifReSTXvfkGBNR/r79EO2d3X51uXkU5Wdx+Hg7m/cPrDl+ympcYb+51JfCvAxaO7rYuNdKrk3f/E0mv8Q9zM0uEXlERKYHMSZj+m15SR1jRyQwZ9wov7cpzMsgNlp4fQDdcHqsrYOqwydCPnOpPy6ZlH6q5NqYvviVfFT176r6T8D5wF5glTNnzl0iEhvMAI3pS1NLO2/vauDqc8cS5UeXm0dKQiyXTE7n9W0DZ46fSCw28BgWF81FE1Ot6MD4xe9uNGe06Ttx38i5Gfhv3MloVVAiM8ZPr207SEeXcs3ssf3etig/i71HWqisPx6EyAJvq1NsEIndbuAe7WC3lVwbP/h7zecl4G0gEbhGVa9V1T+q6peB5GAGaExflpfUMSEtkVnZw/u97aL8LIAB0/VWWu1izIgEMlJ8zSQSfqdKrnda15s5PX/PfP5HVfNV9WFVrfNeYDODmnA6fPwk63Yf5prZY89oaoGs4QmcO24kr28bGBPMbY2gkQ18mZSexLjUYazdYV1v5vT8TT4zRGSk54Uz6vSXghSTMX57payObuVDM5b2V1F+FiXVLg662gIYWeA1O8UGkZx8RITCaZlWcm365G/yuVtVmzwvnOmq7w5OSMb4b3lJHVMzk8nLSjnjfVw50931tmp7ZHe9batpBiJjJOvTsZJr4w9/k0+UePVpiEg0EBeckIzxT52rlY37Grnm3DPrcvOYnJHMxPSkiO96K6tx//0XyWc+AJdMTiMu2kquzen5m3xeA14UkctFZCHwPGBz4piwerm0DlV8zljaHyJCUX4W66uO0NzWEaDoAq+sppnskcNIS47MYgOPxLgYLppkJdfm9PxNPt8B3gC+CNwLrAa+HaygjPHHitI6Zo4dzqSMsy+4LJqZRUeXRvRf62XVTRF/1uOxYFqGlVyb0/L3JtNuVf2lqt6sqjep6q9Vtc+riSKyWEQqRKRSRO73sXyCiKwWkVIRWSsiOV7LupwZSbeIyDKv9qdFZI/XsvOcdhGRnznHKhWR8722uUNEdjmPO/x5zyayHWhsYcuBJq4+g3t7fDlv3CjSk+MituvN1drB3iMtEX+9x6MwLxOwkmvTO3/v85kqIktFpFxEqjyPPraJBh4HrgLygVtFJL/Hao8Bz6rqbGAJ8LDXslZVPc95XNtju295LdvitF0FTHUe9+AeEggRSQW+B1wEzAW+JyL+j8FiItLy0lrg7LvcPKKjhCtmZLG2ooGTnZFXpbUtAkeyPp3JGUnkjBrGm9b1Znrhb7fbU7h/mXcClwHPAr/rY5u5QKWqVqlqO/ACcF2PdfJxd+EBrPGxvD+uw53IVFXXAyNFZAxwJbBKVRudKr1VwOKzOI6JACtK6pgzfiTjUhMDts+imVkcP9nJ+qrIq9KKxGkUTsd7lOtITOYm/PxNPsNUdTUgqrpPVb8PLOxjm2zggNfraqfNWwlwk/P8BiDFGcYHIEFEikVkvYhc32O7h5yutZ+IiOfqa2/H8ycOM4DsbjhOeV1zwLrcPOZNTicxLjoiu95Ka1zkjBrGqKSBU2R6WV4mLe1dbNwzsEYNN6Hhb/Jpc6ZT2CUi94nIDUBmH9v4qn3tOXrjN4EFIrIZWADU4D67AhjvjJ5wG/BTEZnstD8ATAcuBFJxF0Oc7nj+xOHegcg9TsIrbmiwvupItaKkDhH45DmB6XLzSIiNZsG0DFaVH6I7wub4KauO7JENfPmg5Nq63sxH+Zt8vop7XLevABcAnwX6unBfDYzzep0D1HqvoKq1qnqjqs4Bvuu0uTzLnJ9VwFpgjvO6zulaO4m7O3BuH8frMw6veJ5Q1QJVLcjIyOjj7ZlwUFWWldRwYW4qo0cEfjK1oplZ1B87SanTzRUJXC0d7G8cOMUGHqdKrq3owPjQZ/JxCgc+rarHVbVaVe9yKt7W97HpRmCqiEwUkTjgFmCZ9woiku41Qd0DwJNO+yhPd5qIpAPzgXLn9RjnpwDXA1ud7ZcBn3Oq3i4GXM44dK8BRc4+RwFFTpsZgHYcPMbuhhNcc25gu9w8FuZlER0lEdX1NtCu93hbMC2DyvrjVB+1kmvzYX0mH6ek+gLvEQ78oaqdwH24f9FvB15U1W0iskREPNVrhUCFiOwEsoCHnPYZQLGIlOAuRHhEVcudZc+JSBlQBqQD/+G0rwSqgErgN8CXnDgagR/gToYbgSVOmxmAVpTWEh0lXDVrdFD2PyIxlosmpkbUKNcDOfmcKrmO4PunTHjE+LneZuBvIvIn4ISnUVVfOt1GqroSd1LwbnvQ6/lSYKmP7dYB5/SyT5+FDuqeDezeXpY9iXNWZQYuVWV5SR3zJqeRHsS7/Ivys/j+8nKqGo4H5AbWs1VW08S41GGMTBw4xQYenpLrtRUNfPbiCeEOx0QQf6/5pAJHcFe4XeM8rg5WUMb4UlbjYn9jyxlNGtcfi2a6z6pWRcjZT1mNi9nZI/teMQJ9UHJ92EquzYf4O8LBXT4enw92cMZ4W15SS2y0cOXM4HS5eWSPHMas7OER0fV29EQ7BxpbB1yxgbfCae6S6+K9VnJtPuBXt5uIPIWP8mRLQCZUuruVFaV1XDo1gxGJsUE/3qIZo/np6p00HDsZ1llDt9YO3Os9HvOmfFByPX9KerjDMRHC3263FcDLzmM1MBwYGJPem0Hh/f1HqXO1Ba3KraeimVmowuowz/FTWu1OPrPGDtzkkxgXw9yJqVZ0YD7E3263P3s9ngM+DcwKbmjGfGB5SS3xMVFckZ8VkuNNH53CuNRhYe9621rjYkJaYkjO9oKpMC+DXfXHqWlqDXcoJkL4e+bT01RgfCADMaY3Xd3Ky2UHWTg9k+R4fws0z46IsGjGaP5ReZgTJzv73iBISgfgyAa+FOa5b9q20Q6Mh7+jWh8TkWbPA1jOB8PaGBNUG6qOcPj4yYCP5daXoplZtHd281aY7tBvPNFOTVProEg+kzOSyR45zLrezCn+drulqOpwr8c0Vf1zsIMzBtzTJyTGRbNwel/DCQZWwYRRjEqMDVvX26mbSwdwpZvHqZLrysO0d3aHOxwTAfw987lBREZ4vR7pY6RpYwKuo6ubV7YeZFF+FsPiokN67JjoKC6fkcXq7Yfo6Ar9L8yy6iYAZg2CMx9wj3Zwor2L4r02wIjx/5rP9zwDfgKoahPuCdqMCap/VB6mqaUj5F1uHovys2hu6+S9PaH/hVlW42JiehLDEwZ2sYHHPM8o1zbQqMH/5ONrvdBc+TVD2vKSWlISYrh0WnjuD7l0agYJsVFhGe2grNo1aM56AJLiY7hw4igrOjCA/8mnWER+LCKTRWSSiPwE2BTMwIxp6+hi1bZDLJ45mviY0Ha5eQyLi+bjUzN4fdtB3MMHhsbh4yepdbUxexAlH3CPdrDz0HFqreR6yPM3+XwZaAf+CLwItNLLIJ7GBMqbOxs4drKTq0N0Y2lvFuVnUetqY1ttc8iOOZiKDbx9UHJtXW9Dnb/VbidU9X7PRGuq+n9V9UTfWxpz5laU1pGaFMe8yWl9rxxEl0/PJEoIadXbVmdkg5ljh4fsmKEwJdNTcm1db0Odv9Vuq0RkpNfrUSJiE7KZoGlp7+Tv5YdYPGs0sdFnei90YKQlx1OQmxrSCeZKa1xMykgiZZAUG3iICAvyMnjHSq6HPH//V6c7FW4AqOpRoM+bLkRksYhUiEiliNzvY/kEEVktIqUislZEcryWdYnIFuexzMe2PxeR416vf+K1/k4RafJ3XybyrN5eT2tHV9CnT/BXUX4WOw4eY/+R0MzIubVmcIxs4EvhtAx3yfU+K7keyvxNPt0icmo4HRHJxcco196c6bcfB64C8oFbRSS/x2qPAc+q6mxgCfCw17JWVT3PeVzrvZGIFAAfmuBEVb/mWR/4OfCSP/sykWlFaS2ZKfHMnZga7lAAKMp3T+Pwennwz34ajp2kztU2aJPPvCnpxEYLb9p1nyHN3+TzXeAfIvI7Efkd8CbwQB/bzAUqVbVKVduBF4DreqyTj3uUbHBPl91z+Uc4Se1R4NunWe1W4Pm+9mUi07G2DtZUNPCJc8YQHdWv2duDZnxaItNHp4Sk5HrrAJ422x/J8TFcmGujXA91/hYcvAoUABW4K96+gbvi7XSygQNer6udNm8lwE3O8xuAFBHxXF1OEJFiEVnfYzSF+4Blqlrn66AiMgGYCLzh1dzbvkwEWlV+iPbO7pBNn+CvovwsNu5tpPFEe1CPU1rtQgRmDtLkA+6qt4qkSCVeAAAgAElEQVRDx6zkegjzt+DgC7jPUL7hPH4HfL+vzXy09eyq+yawQEQ2AwuAGsAzhPB4VS0AbgN+6txjNBb4FO5utd7cAixVVe85ez+yL58Bi9zjJKnihgb7qyxclpfUkj1yGOePj6ypoxflj6Y7BHP8lNU0MSk9KWQjeIdDYZ77kvHqHVb1NlT52+32r8CFwD5VvQyYA/T127kaGOf1Ogeo9V5BVWtV9UZVnYO7aw/PMD6qWuv8rALWOsecA0wBKkVkL5AoIpU9jnsLPbrcetnXR6jqE55y8oyMjD7engmGoyfaeXvXYa6ePQaRyOhy85iVPZwxIxKC3vVWVuNidk5kJd5Am5qZzPTRKTy3fl9Ib941kcPf5NOmqm0AIhKvqjuAvD622QhMFZGJIhKHOyl8qNJMRNJFxBPDA8CTTvsoEYn3rAPMB8pV9WVVHa2quaqaC7So6hSv/eUBo4B3vdp87svP921C7LVtB+ns1ojrcgN3mXBRfhZv7Wqgtb2r7w3OQH1zG4eaTw6qYXV8ERHunJfLjoPHwjJungk/f5NPtXOfz1+BVSLyN3qcxfSkqp24r8+8BmwHXlTVbSKyREQ8FWeFQIWI7ASygIec9hm4h/QpwV2I8Iiq+pMwbgVe0A//KXWm+zJhsLy0lty0xIi9ubJo5mjaOrp5e1dwumU9IxvMHmQjG/hy3XnZjEyM5el1e8MdigkDvzqVVfUG5+n3RWQNMAJ41Y/tVgIre7Q96PV8KbDUx3brgHP82H9yj9ffP9N9mfBrOHaSd3cf4d7LpkRcl5vH3ImpDE+IYVX5IYpmjg74/kurXUQJ5I+JzOQbSMPiovnMheP437f3UNPUSvbIYeEOyYRQv28dV9U3VXWZUz5tTMC8srWObiVs0yf4IzY6ioXTM/n79kN0BmGOn601LiZnJJM0iIsNvN1+8QRUld+v3xfuUEyIhXfcEmO8LC+pZVpWMnmjU8IdymkVzRzN0ZYONu07GvB9l9a4Bt1goqeTMyqRRflZPP/efto6gnMdzUQmSz4mItS5Wtm492jEDKdzOpdOyyAuOirgA40eam6j4djJQXtzaW/unDeRppYOlm057WVkM8hY8jER4eVS9z3D4Z4+wR/J8THMn5LGqvJDAS0TLq0eOsUG3i6elEpeVgpPrdtrZddDiCUfExGWl9QyK3s4E9OTwh2KX4pmjmZ/YwsVh44FbJ9lNZ5ig6GVfESEO+fnsr2umY17A9+VaSKTJR8TdvuPtFBS7YroQoOeLp+RiQi8vi1wXW9l1U1MzUxhWFx4Zm0Np+vPy2bEsFieXrcn3KGYELHkY8Jueam7r/+T54wJcyT+y0xJYM64kQEb7UBVKatxDfqbS3szLC6aWy4cx2vbDtl4b0OEJR8TditK6zh//EjGpSaGO5R+KZo5mrIaV0B+WR5sbuPw8fYhd73H22et7HpIseRjwqqy/hjb65oHVJebR1F+FkBAzn48xQZD9cwHYFxqIlfMsLLrocKSjwmr5SV1iMAnZw+cLjePSRnJTM5ICsgEc1trXERHyZAY2eB07pyfy9GWDpaVWNn1YGfJx4SNqrKitJa5ualkDU8IdzhnpGjmaDZUNeJq6Tir/ZRWu5iamTwkiw28XTIpjbysFJ5+x8quBztLPiZsttcdY3fDiYgcwdpfRflZdHYrayrOfF4aVWVrjWvI3Vzqi4hwx7xcyuuaKQ7CCBImcljyMWGzorSW6CjhqlmBH6AzVM7NGUlmSvxZdb3Vuto4cmJoFxt4u37OWHfZ9Tt7wx2KCSJLPiYsVJXlpbXMm5xGWnJ8uMM5Y1FRwhX5WbxZ0XDGF8nLrNjgQxLjYvjMheN4ddtB6lxWdj1YWfIxYVFS7eJAY+uA7nLzKMrP4kR7F+/uPnJG25fVNBETJcwY4sUG3obaaNeqyqHmtnCHEVKWfExYrCipJTZauDJ/4Ha5eVwyOY3k+Jgz7norq2lmalYKCbFDu9jA27jURC6fkcXz7x0YEmXXP1tdycUPr+Z/364KdyghE9TkIyKLRaRCRCpF5H4fyyeIyGoRKRWRtSKS47WsS0S2OI9lPrb9uYgc93p9p4g0eG3zBa9ld4jILudxRzDeq/Ffd7eyorSOBdMyGJEYG+5wzlp8TDQL8jJYVV5Pd3f/KrRUlbLqJmZbl9tH3DUvl8YT7Swf5GXXNU2t/GJtJcMTYvmPl7fz78u30dXP79FAFLTkIyLRwOPAVUA+cKuI5PdY7THgWVWdDSwBHvZa1qqq5zmPa703EpECYKSPw/7Ra5v/ddZNBb4HXATMBb4nIqMC8BbNGdq0/ygHm9sGRZebR1F+FoePn2TzgaZ+bVfT1MrRlg5mWbHBR1wyOY1pWck8PchHu/7hqzsAWPHlj/HPH5vIU+/s5UvPbRr0Z3zBPPOZC1SqapUz6+kLwHU91skHVjvP1/hY/hFOUnsU+LafcVwJrFLVRlU9CqwCFvu5rQmC5SW1xMdEcfmMrHCHEjCXTc8kNlr63fXmKTawM5+P8pRdb6ttDsrEfZFg076j/G1LLfdcOolxqYn8v6vzefDqfF4vP8Stv1nPkeMnwx1i0AQz+WQDB7xeVztt3kqAm5znNwApIpLmvE4QkWIRWS8i13ttcx+wTFXrfBzzJqcLb6mIjOtHHCZEOru6WVlWx+UzMkkeRFNFD0+I5eJJaazq5yjXpTUuYqOF6WMie/bWcLlhTjbDE2J4at3ecIcScN3dyg9WlJOZEs+/LJh8qv3zH5vIL//pfMprm7npl+vYe/hEGKMMnmAmH/HR1vPc+ZvAAhHZDCwAaoBOZ9l4VS0AbgN+KiKTRWQs8Cng5z72vRzIdbrw/g4804843CuK3OMkvOKGhobTvDVzpjbsaeTw8fYBMWNpfxXlZ1F1+ASV9cf7XtmxtcbFtKwU4mOs2MCXU2XXWwdf2fWyklq2HGji24unk9TjD7HFs8bwh7svwtXawY2/XMf7+wffmV8wk081MM7rdQ7woSuHqlqrqjeq6hzgu06by7PM+VkFrAXmOI8pQKWI7AUSRaTSWe+IqnrOUX8DXOBvHF7xPKGqBapakJGRcSbv2fRheUktSXHRXDY9M9yhBNwVzkCj/na9qSql1S67ubQPn7skl25Vnlu/P9yhBExLeyePvLKD2TkjuHGO746YCyak8tKX5pOSEMNtv1nPa9vOfgzBSBLM5LMRmCoiE0UkDrgF+FDVmoiki4gnhgeAJ532USIS71kHmA+Uq+rLqjpaVXNVNRdoUdUpznreI1NeC2x3nr8GFDn7HAUUOW0mxNo7u3l120EW5WcNyrLiMSOGcW7OCL8nmKs+2oqrtcNuLu3DuNRELp+exR8G0WjXT7xVxcHmNh68Op+oKF+dM24T05P48xfnMX30cP7l95t4+p3BM9le0JKPqnbivj7zGu5E8KKqbhORJSLiqV4rBCpEZCeQBTzktM8AikWkBHchwiOqWt7HIb8iItucbb4C3OnE0Qj8AHcy3AgscdpMiL1TeZimlo4BOX2CvxblZ7HlQBP1ftwwWHqq2MBX4abxdtd8d9n1ilJfl3oHljpXK796czdXzx5DQW5qn+unJ8fz/N0Xc8WMLL6/vJyHXi7vd0l/JArqFV9VXQms7NH2oNfzpcBSH9utA87xY//JXs8fwH325Gu9J3HOqkz4LC+pZXhCDB+flh7uUIKmaOZoHnt9J6u2H+KfLppw2nXLnGKDaaOTT7uegXmT05iamczT6/Zw0/nZiPR+thDpfvhqBd0K91813e9thsVF86vPXsCS5dv4zdt7qG1q40efPndA9yDYCAcmJNo6uni9/BCLZ40e1BfXp2Ymk5uW6FfXW1lNE9NHDx/Un0egeMqut9Y0D+iL75v3H+Uvm2u45+OTyBnVv5l7o6OE7187k+9+YgYvl9Vx+2830NTSHqRIg8+SjwmJtRUNHD/ZOai73MD9S3JRfhbrdh/mWFvvc/y4RzZw2fWefrjx/GxSEmJ4aoCOdq2qLFlRTkZKPF8snNz3Bj6ICHdfOon/uW0OJQdc3PjLdRxobAlwpKFhyceExPLSWlKT4pg3Oa3vlQe4opmj6ehS3tzZe7n+/sYWmts6rdKtHxLjYvhMgbvs+qBr4A3Cuaykls37m/j2lXkfKa3ur6tnj+X3X7iII8fbueEX71Ba3b+RNSKBJR8TdC3tnbyxvZ6rZo0mJnrwf+XOHz+KtKS403a9ldW4iw1sArn++dwluXSp8tyGgTXadWt7F4+8soNZ2cO56fycvjfww9yJqfz5i/NIiI3mM79ez+rt/bvBOdwG/28CE3Z/315Pa0fXoBrL7XSio4QrZmSxZkc97Z3dPtcpq3YRFx3FtCwb2aA/xqclcvn0TP6wYT8nOwdO2fUTb1VR52rjwatnnra0ur+mZCbz0pfmMSUzmbufLR5QU1BY8jFBt6Kklqzh8VzoR1npYLEoP4tjJzvZsMf3HD+l1S5mjEkhLsb+C/bXnfMmcuREOytKBkbZtae0+pPnjGHuxMD/H8hMSeCFey6mMC+Tf/vrVv7r1R0DohTbvvkmqJrbOlhb0cAnzhlDdAD/4ot0H5uazrDYaJ9db93dytZaKzY4U/OnpDElc+CMdv3oqxV0qfartLq/kuJjeOL2C7jtovH8cu1uvvbilog/M7TkY4Lq9W2HaO/qHjJdbh4JsdEsmJbBqvJDH/krdF9jC8es2OCMecquy2pcvL8/si+0bznQxEuba/jCxyYyLrV/pdX9FRMdxUPXz+Lbi/P425ZaPvfb93C19F5xGW6WfExQrSitJXvkMOaMG3p38S/Kz+Jgc9up4gIPz2s78zlzN85xl10/HcGjXasqS5ZvIz05ni9dNiUkxxQRvlQ4hf++5Tze33+Um3+1juqjkVmKbcnHBM3RE+38Y9dhrj53zIC+I/1MLZyeSXSUsKr8w11vZdVNxMVYscHZSIqP4dMF43ilrI5DfgxlFA7LS+t43ymtDvX0Idedl80zn5/LweY2bvjFOrb2+AMoEljyMUGh6p6rpLNbue7coTl90qikOObmpn5klOuyGhczxgwndgiUnQfT5y6Z4C67jsAKr7aOLh5ZuZ2ZY4dz0wWBKa3ur3mT0/nzF+cRGyV8+tfvsraiPixx9Ma+/SYofra6kpc21/D1RdPIHzs83OGETdHMLHYeOn5qQrDubmVrTbPNXBoAE9KSWJiXyR/ei7yy69+8VUWtq43/d3V+WAttpmWl8Jd755OblsQ/P1PMHzdGzrQUlnxMwP1tSw0/+ftObjw/my8vDE1fd6Ra5Mzx4+l623vkBMdPdtrNpQFy5/xcDh9v5+UIGu36UHMbv1i7m6tmjebiSeEf0SNreAIv/sslzJ+Sznf+XMaPX6+IiCpBSz4moDbubeRbfypl7sRUHr7xnCF5rcdbzqhE8scMP9X1dmpkA6t0C4iPTUlnckZSRJVd//DVCrq6lQeumhHuUE5Jjo/ht3cU8JmCcfzsjUq+8WJJrzdAh4olHxMwew+f4J5ni8kZNYwnbr/ARmt2FM3MonjfUQ4fP0lZtYv4mCimZto0CoEgItw5L5fSahebD4S/7Lq0uok/v1/N5z82kfFpwS2t7q/Y6Cgeuekcvr5oGi9truGup9+j+TSD3wabJR8TEE0t7Xz+6Y0APHnnhYxMjAtzRJFjUX4WqvDG9npKa1zkjx0+JMa4C5Ubz88hJT6Gp8M82rW7tLqc9OQ47r3szEatDjYR4SuXT+WxT53LhqpGPv2rd6lztYYllqD+DxCRxSJSISKVInK/j+UTRGS1iJSKyFoRyfFa1iUiW5zHMh/b/lxEjnu9/rqIlDv7Wi0iE/zdlzk77Z3d/J/fbaL6aCtPfK6A3PSkcIcUUfLHDCd75DBe3XaQbTUuKzYIsKT4GD5VMI6VYS67frmsjuJ9R/lmUR4pCbFhi8MfN1+Qw9N3zaX6aCs3PL6O7XXNIY8haMlHRKKBx4GrgHzgVhHJ77HaY8CzqjobWAI87LWsVVXPcx7Xem8kIgVAz7sWNwMFzr6WAj/0Z1/m7Kgq979UyoY9jfzw5tlDavw2f4kIRTOzWFNRz4n2Lru5NAhOlV1vCE81V1tHFw+v3EH+mOF8qmBcWGLor49NTedP/3IJAJ/61bu8vav3KUCCIZhnPnOBSlWtUtV24AXguh7r5AOrnedrfCz/CCepPQp827tdVdeoqudW3vVAeIrrh5j/eaOSl96v4atXTOX6OUPzfh5/FOWPxnM9fHbO0BvtIdhy05O4LC98o13/9h97qGlqDXtpdX/NGDOcv9w7j5xRw7jrqY38qfhAyI4dzOSTDXi/k2qnzVsJcJPz/AYgRUQ8tYkJIlIsIutF5Hqvbe4Dlqnq6Wor/xl4xet1b/v6EBG5x1mvuKEhtH8FDER/21LDj1bt5IY52fzr5VPDHU5EuzB3FCMTY0mIjWJyhnVLBsOd83I5fPwkK8tCW3Zd39zG42sqWTxzNJcMwMkSx4wYxov/cgkXTUrlW0tL+e+/7wpJ5WAwk4+v9N/zHX0TWCAim4EFQA3Q6Swbr6oFwG3AT0VksoiMBT4F/LzXg4p8FijAfXbk8ZF9+dpWVZ9Q1QJVLcjIyOj7HQ5hm/Y18q2l7pLqR26ykuq+xERHcfvFE7hm9lgrNgiSj01JZ1JGUsgLDx59rYLOLuWBTwRv1OpgG54Qy1N3zuXG87NZUVpLS3vwzx6DOeBQNeDd+ZkD1HqvoKq1wI0AIpIM3KSqLq9lqGqViKwF5gCtwBSg0vlllygilao6xdnHFcB3gQWqerLHcXrua3eA3++Qse/ICe5+dhPZI4fx689aSbW/vlGUF+4QBrWoKHfZ9YN/28bm/UeZM35U0I9ZVu1i6fvV3HPpJCakDewz2riYKH70qXNxtXac9TTf/gjmn2AbgakiMlFE4oBbgA9VmolIuoh4YngAeNJpHyUi8Z51gPlAuaq+rKqjVTVXVXOBFq/EMwf4NXCtqtZ7HcPnvoL2rgc5V0sHdz29kW5VnrzzQkYlWUm1iRynyq5DMNq1Z/zCtKQ47gvRqNXBJiIhu00iaMlHVTtxX595DdgOvKiq20RkiYh4Ks4KgQoR2QlkAQ857TOAYhEpwV2I8Iiq9pUwHgWSgT/1KKk+k30ZH9o7u/k/vy/mQGMLv/7sBUy0kmoTYZLjY7i5IIeVZXXUB7ns+pWtB3lvbyPfGACl1ZFIImVIikhTUFCgxcXF4Q4jYqgq31paytJN1fzkM+dywxwrJjSRae/hE1z2o7V8ZeFUvrZoWlCO0dbRxRU/fpPk+Bhe/srHB1SFWzCJyCbn+nqf7Mqn8csv1u5m6aZq/vXyqZZ4TETLTU+icFoGz23YH7Txy377jz1UH23lwWsGVml1JLHkY/q0vKSWR1+r4PrzxvLVK6yk2kS+O+dPDFrZdX1zG79YU0lRfhbzJqcHfP9DhSUfc1qb9h3lG38q4cLcUfzXzbOtpNoMCB+fks6k9CSeCkLhwWOvV9De1c3//UTkjFo9EFnyMb3af6SFu58tZsyIBH59e4GVVJsBIypKuGNeLiUHmti8/2jA9ru1xsWfNlVz1/yJNobhWbLkY3xyl1S/R1e38tSdF5JqJdVmgLnpghyS42N4JkBnP6rKkhXlpCbGcd8QnyQxECz5mI9o7+zmi89tYn9jC0/cfgGTMmzuGTPwJMfHcPMFObxcVkf9sbMvu35160He29PI14umMdxKq8+aJR/zIarKv/21jHW7j/DIjbO5KAKmATbmTN0xL5eOLuUPZznadVtHF//5ynamj07hMwNk1OpIZ8nHfMgv39zNi8XVfGXhFG66wEqqzcA2MT2JwryzL7t+6p29HGh0j1ptY/MFhn2K5pSXS+v44asVXHvu2KDdnGdMqN05L5eGYyd5ZeuZlV3XH3OPWn3FjCzmT7HS6kCx5GMAeH//Ub7+4hYKJozih1ZSbQaRS6dmMDE9iafOcLTrH7++k5OdXXz3k1ZaHUiWfAwHGlu4+5liRo9I4Ne3X0BCrJVUm8EjKkq445IJbDnQxJYDTf3adlutiz8WH+COS3JtLMMAs+QzxLla3aNUd3a7R6lOS44Pd0jGBNyZlF2rKkuWlzNyWCxftskSA86SzxDW0dXNl57bxL4jJ/jVZy9gspVUm0EqJSGWmy/IYUVprd9l169tO8SGPY18vSiPEcOstDrQLPkMUarK//vrVt6pPMLDN84ekNP/GtMfn7tkAh1dyvMbDvS57snOLv5z5XbyslK49UIrrQ4GSz4B9oVninno5XLW7T5MR1dwRtQNhF+/VcULGw9w32VTuNlKqs0QMCkjmQXTMnhuw74+y66ffmcv+xtb+LerZ1hpdZAE9VMVkcUiUiEilSJyv4/lE0RktYiUishaEcnxWtblTArnPTGc97Y/F5HjXq/jReSPzrE2iEiu17IHnPYKEbky8O/UrbW9i7aOLp5et5fbfrOB85es4kvPbeJPxQdoOHay7x2EyMqyOh55ZQfXnDuWr1tJtRlC7pyfS30fZdcNx07y8zcquWJGJh+fmhHC6IaWoE3ULSLRwOPAIqAa2Cgiy3rMIvoY8KyqPiMiC4GHgdudZa2qel4v+y4ARvZo/mfgqKpOEZFbgP8CPiMi+bin8J4JjAX+LiLTVLUrMO/0A8Piovn9Fy7i+MlO3qk8zJod9aypqGdl2UEAZueM4LK8TBZOz+Sc7BFEhWEekM37j/K1P27hggmjePTm2WGJwZhwWeCUXT+9bi/XnZftc50fr9pJW0eXjVodZEFLPsBcoFJVqwBE5AXgOsA7+eQDX3OerwH+2tdOnaT2KHAbcIPXouuA7zvPlwL/I+6bVa4DXlDVk8AeEal0Ynv3zN5W35LjY7hy5miunDkaVWVbbfOpRPSzN3bx36t3kZ4cT2FeBgunZ/KxqekhGSvqQKN7lOqs4Qk8YSXVZgiKihI+d8kE/n15OSUHmjh33If/hi2vbeaPG/dz1/yJNqZhkAUz+WQD3lf2qoGLeqxTAtwE/DfuRJIiImmqegRIEJFioBN4RFU9iek+YJmq1vW4EfLU8VS1U0RcQJrTvr5HHL7/5AkCEWFW9ghmZY/gy5dPpfFEO2/urOeNHQ28vu0gSzdVExMlFOSOYuF091nR5IzkgN/k2dzWweef3kh7Zzcv3GMl1WbouvmCHB57rYJn1u3lx5/5oHNFVfnBinJGDIvlKwuttDrYgpl8fP321B6vv4n7DOVO4C2gBneyARivqrUiMgl4Q0TKgFbgU0BhP47nTxzuHYjcA9wDMH78eF+rnLXUpDhumJPDDXNy6OzqZvOBJt7YUc+aHfX858od/OfKHYxLHcZleZlcNj2TSyalnfUZSkdXN/c+9z57Dp/g2c/PZUqm/UVnhi5P2fXz7x3ggU/MICPF/YfYqvJDvFt1hB9cN5MRiVZaHWzBTD7VgHeNYg5Q672CqtYCNwKISDJwk6q6vJahqlUishaYgzv5TAEqnTODRBGpVNUpXserFpEYYATQ6E8cXvE8ATwBUFBQ4DNBBVJMdBQX5qZyYW4q31k8nZqmVtbsqGdtRT0vFh/g2Xf3kRAbxfzJ6Vw23Z2MskcO69cxVJUH/7aNt3cd5oc3z2aejU1lDJ+bl8sz7+7j+ff285XLp3Kys4uHVm5namYyt84Nzh+e5sOCmXw2AlNFZCLuM5pbcF+nOUVE0oFGVe0GHgCedNpHAS2qetJZZz7wQ6dYYbTX9sedxAOwDLgD97Wcm4E3VFWdSrk/iMiPcRccTAXeC9abPhvZI4fx2Ysn8NmLJ9DW0cX6qiOs2VHPGxX1rN5RD8D00SkUOkUL548f2WcZ6G/eruL59/Zz72WT+bQNBW8MAJMzkrl0Wga/X7+PLxZO5tl1+9h3pIVnPz/XSqtDJGjJx7nuch/wGhANPKmq20RkCVCsqstwd589LCKKu9vtXmfzGcCvRaQbdzn4Iz2q5Hz5LfA7p6CgEXeywznmi7gLHTqBe4NR6RZoCbHRFOZlUpiXyfdV2d1wnDU7GnhjRz3/+3YVv3pzNyOGxXLptAwWTs9gwbTMj8w2+urWOh5+ZQdXzx7DNxblhemdGBOZ7pqXy11Pb+T36/fxs9W7WDg9k0unWWl1qIhq0HuXBqSCggItLi4Odxg+Nbd18I9dh3ljRz1rKxo4fPwkIjBn3MhT14o6u5VbnniXGWOG8/zdF1tlmzE9dHcrC3+0ln2NLUSL8OpXL7XroWdJRDapaoFf61ry8S2Sk4+37m5la63rVNFCSbULABHIGTWMv3xpPulW2WaMT0/+Yw9LVpRz1/xcvnfNzHCHM+D1J/kE85qPCYGoKGF2zkhm54zkq1dMo+HYSd7c2UDx3kbuvnSSJR5jTuPWueNp6+zi9osnhDuUIcfOfHoxUM58jDEmUvTnzMfKOowxxoScJR9jjDEhZ8nHGGNMyFnyMcYYE3KWfIwxxoScJR9jjDEhZ8nHGGNMyFnyMcYYE3J2k2kvRKQB2HeGm6cDhwMYTrBYnIE3UGK1OANroMQJwY11gqr6NTqrJZ8gEJFif+/yDSeLM/AGSqwWZ2ANlDghcmK1bjdjjDEhZ8nHGGNMyFnyCY4nwh2AnyzOwBsosVqcgTVQ4oQIidWu+RhjjAk5O/MxxhgTcpZ8+kFEnhSRehHZ6tX2fRGpEZEtzuMTvWy7WEQqRKRSRO4PQ5x/9Ipxr4hs6WXbvSJS5qwX1AmNRGSciKwRke0isk1E/tVpTxWRVSKyy/k5qpft73DW2SUid4QhzkdFZIeIlIrIX0RkZC/bR8JnGlHf09PEGVHfUxFJEJH3RKTEifPfnfaJIrLB+e79UUTietn+AeezrBCRK8MQ53POsbc6vxdie9m+y+tzXxasOD9EVe3h5wO4FDgf2OrV9n3gm31sFw3sBiYBcUAJkB/KOHss/xHwYC/L9gLpIVpAFXMAAAUGSURBVPo8xwDnO89TgJ1APvBD4H6n/X7gv3xsmwpUOT9HOc9HhTjOIiDGaf8vX3FG0GcaUd/T3uKMtO8pIECy8zwW2ABcDLwI3OK0/wr4oo9t853PMB6Y6Hy20SGO8xPOMgGe9xWns83xUHw/vR925tMPqvoW0HgGm84FKlW1SlXbgReA6wIanJfTxSkiAnwa9xcxrFS1TlXfd54fA7YD2bg/m2ec1Z4Brvex+ZXAKlVtVNWjwCpgcSjjVNXXVbXTWW09kBOM4/fHaT5Tf4Tse9pXnJHyPVW3487LWOehwEJgqdPe23f0OuAFVT2pqnuAStyfccjiVNWVzjIF3iMCvqMelnwC4z6n6+XJXrqIsoEDXq+r8f8XQqB9HDikqrt6Wa7A6yKySUTuCVVQIpILzMH9F1uWqtaB+5cUkOljk7B8pj3i9PZ54JVeNouEzxQi9Hvay2caMd9TEYl2uv/qcf+Rsxto8vrDo7fPKaSfZ884VXWD17JY4Hbg1V42TxCRYhFZLyK+EmnAWfI5e78EJgPnAXW4uwp6Eh9t4SozvJXT/zU5X1XPB64C7hWRS4MdkIgkA38Gvqqqzf5u5qMtqJ9pb3GKyHeBTuC5XjaNhM80Ir+np/m3j5jvqap2qep5uM8a5gIzfK3moy2kn2fPOEVkltfiXwBvqerbvWw+Xt2jHtwG/FREJgcrTg9LPmdJVQ85/+jdwG/wfVpdDYzzep0D1IYiPm8iEgPcCPyxt3VUtdb5WQ/8hSB1E3jFFIv7l89zqvqS03xIRMY4y8fg/kuup5B+pr3EiVPocDXwT07XxkdEwmcaid/T03ymEfc9dY7VBKzFfS1lpBMn/P/27hg0iiAMw/D7NwYJIlFTaGeRVhCs1FJCTBFQLCIWomdhJSiCRQrFPmIjWCiIllamECzEXgtNjCZitBLsLAUxsBYzGy5yl+aS2Vt4H1jusrdDvkzm7r/MTvb691Mjz/uunFMAEXEbGAdubNGm7s/vue3Rnc5p8RlQ/SKZnQGWexz2DpjIK2R2AbNAmRUlm50CVquq+tHrwYgYjYg99X3SCfVeP8+2yPP6j4GVqqrudT20ANSr1y4CL3o0fwVMRsRYnkKazPuK5YyIKeAWMFNV1e8+bYeiT4dtnG7xu4chGqcRMR55FWNE7M7ZVoA3wLl8WL8xugDMRsRIRBwGJkjnXUrlXI2IK6Tzo+fzG49ebcciYiTfPwCcAD7vRM5NSq9waPNGmgb4CfwlvavpAM+Aj8ASabAdzMceAl52tZ0mrej5BsyVzpn3PwGu/nfsRk7SKqfFvH0qkPMkaRpiCfiQt2lgP/Aa+Jpv9+XjjwGPutpfJp3EXQMuNZBzjTSnX+97OMR9OlTjtF/OYRunwBHgfc65TF59lzO8zWPgOTCS988Ad7vaz+W+/AKcbiDnev7+dR/X+zeeS8DxPDYW821nJ8dovXmFA0lScU67SZKKs/hIkoqz+EiSirP4SJKKs/hIkoqz+EgtEBFVRMx3fX0zIu40GEkaiMVHaoc/wNn8T4BS61l8pHZYJ3388fWmg0jbweIjtccD4EJE7G06iDQoi4/UElW66vNT4FrTWaRBWXykdrlPuqbgaNNBpEFYfKQWqarqF+kjnDtNZ5EGYfGR2mcecNWbWs2rWkuSivMvH0lScRYfSVJxFh9JUnEWH0lScRYfSVJxFh9JUnEWH0lScRYfSVJx/wAH2sUPt8eKQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the classifier with optimal values is:  0.973516429622364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(10)\n",
    "kf.get_n_splits(data.X_train)\n",
    "\n",
    "range_ratio = np.arange(0.05, 0.75, 0.025)\n",
    "accuracies_ratio = []\n",
    "for r in range_ratio:\n",
    "    cv_accuracies = []\n",
    "    for indices_train, indices_test in kf.split(data.X_train):\n",
    "        classifier = BaggingClassifier(ratio = r)\n",
    "        classifier.fit(data.X_train[indices_train], data.y_train[indices_train])\n",
    "        outputs = classifier.predict(data.X_train[indices_test])\n",
    "        matches = 0\n",
    "        test_y = data.y_train[indices_test]\n",
    "        for i in range(len(outputs)):\n",
    "            if outputs[i] == test_y[i]:\n",
    "                matches= matches + 1\n",
    "        cv_accuracies.append(matches/len(outputs))\n",
    "    accuracies_ratio.append(sum(cv_accuracies)/len(cv_accuracies))\n",
    "    print(\"Computed the accuracy for ratio : \", r)\n",
    "print('The optimal value of Ratio for the classifier is : ', range_ratio[np.argmax(accuracies_ratio)])\n",
    "    \n",
    "accuracies_N = []\n",
    "N_range = np.arange(15,35,2)\n",
    "for n in N_range:\n",
    "    cv_accuracies = []\n",
    "    for indices_train, indices_test in kf.split(data.X_train):\n",
    "        classifier = BaggingClassifier(N = n)\n",
    "        classifier.fit(data.X_train[indices_train], data.y_train[indices_train])\n",
    "        outputs = classifier.predict(data.X_train[indices_test])\n",
    "        matches = 0\n",
    "        test_y = data.y_train[indices_test]\n",
    "        for i in range(len(outputs)):\n",
    "            if outputs[i] == test_y[i]:\n",
    "                matches= matches + 1\n",
    "        cv_accuracies.append(matches/len(outputs))\n",
    "    accuracies_N.append(sum(cv_accuracies)/len(cv_accuracies))\n",
    "    print(\"Computed the accuracy for N : \", n)\n",
    "print('The optimal value of N for the classifier is : ', N_range[np.argmax(accuracies_N)])\n",
    "    \n",
    "accuracies_depth = []\n",
    "depth_range = range(3,50, 3)\n",
    "for d in depth_range:\n",
    "    cv_accuracies = []\n",
    "    for indices_train, indices_test in kf.split(data.X_train):\n",
    "        classifier = BaggingClassifier(base = DecisionTreeClassifier(max_depth = d))\n",
    "        classifier.fit(data.X_train[indices_train], data.y_train[indices_train])\n",
    "        outputs = classifier.predict(data.X_train[indices_test])\n",
    "        matches = 0\n",
    "        test_y = data.y_train[indices_test]\n",
    "        for i in range(len(outputs)):\n",
    "            if outputs[i] == test_y[i]:\n",
    "                matches= matches + 1\n",
    "        cv_accuracies.append(matches/len(outputs))\n",
    "    accuracies_depth.append(sum(cv_accuracies)/len(cv_accuracies))\n",
    "    print(\"Computed the accuracy for depth : \", d)\n",
    "print('The optimal value of depth for the classifier is : ', depth_range[np.argmax(accuracies_depth)])\n",
    "\n",
    "plt.plot(list(range_ratio), accuracies_ratio)\n",
    "plt.xlabel('ratio')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "plt.plot(list(N_range), accuracies_N)\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()    \n",
    "plt.plot(list(depth_range), accuracies_depth)\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "classifier = BaggingClassifier(base = DecisionTreeClassifier(max_depth = depth_range[np.argmax(accuracies_depth)]), \n",
    "                               N = N_range[np.argmax(accuracies_N)],\n",
    "                               ratio = range_ratio[np.argmax(accuracies_ratio)])\n",
    "classifier.fit(data.X_train, data.y_train)\n",
    "outputs = classifier.predict(data.X_valid)\n",
    "matches = 0\n",
    "for i in range(len(outputs)):\n",
    "    if outputs[i] == data.y_valid[i]:\n",
    "        matches= matches + 1\n",
    "print(\"The accuracy for the classifier with optimal values is: \", matches/len(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Decision Tree [10-points]\n",
    "\n",
    "In this assignment you are going to implement a random decision tree using random vector method as discussed in the lecture.\n",
    "\n",
    "Best split: One that achieves maximum reduction in gini index across multiple candidate splits. (decided by `candidate_splits` attribute of the class `RandomDecisionTree`)\n",
    "\n",
    "Use `TreeNode` class as node abstraction to build the tree\n",
    "\n",
    "You are allowed to add new attributes in the `TreeNode` and `RandomDecisionTree` class - if that helps.\n",
    "\n",
    "Your tasks are as follows:\n",
    "* Implement `gini_index` method which takes in class labels as parameter and returns the gini impurity as measure of uncertainty\n",
    "\n",
    "* Implement `majority` method which picks the most frequent class label. In case of tie return any random class label\n",
    "\n",
    "* Implement `find_best_split` method which finds the random vector/hyperplane which causes most reduction in the gini index. \n",
    "\n",
    "* Implement `build_tree` method which uses `find_best_split` method to get the best random split vector for current set of training points. This vector partitions the training points into two sets, and you should call `build_tree` method on two partitioned sets and build left subtree and right subtree. Use `TreeNode` as abstraction for a node.\n",
    "\n",
    "> The method calls itself recursively to the generate left and right subtree till the point either `max_depth` is reached or no good random split is found.  When either of two cases is encountered, you should make that node as leaf and identify the label for that leaf to be the most frequent class (use `majority` method). Go through lecture slides for better understanding\n",
    "\n",
    "* Implement `predict` method which takes in multiple data points and returns final prediction for each one of those using the tree built. (`root` attribute of the class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.isLeaf = False\n",
    "        self.label = None\n",
    "        self.split_vector = None\n",
    "\n",
    "    def getLabel(self):\n",
    "        if not self.isLeaf:\n",
    "            raise Exception(\"Should not to do getLabel on a non-leaf node\")\n",
    "        return self.label\n",
    "    \n",
    "class RandomDecisionTree:\n",
    "            \n",
    "    def __init__(self, candidate_splits = 100, depth = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            candidate_splits (int) : number of random decision splits to test\n",
    "            depth (int) : maximum depth of the random decision tree\n",
    "        \"\"\"\n",
    "        self.candidate_splits = candidate_splits\n",
    "        self.depth = depth\n",
    "        self.root = None\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_train (ndarray): [n_samples x n_features] ndarray of training data   \n",
    "            y_train (ndarray): [n_samples] ndarray of data\n",
    "            \n",
    "        \"\"\"\n",
    "        self.root = self.build_tree(X_train[:], y_train[:], 0)\n",
    "        return self\n",
    "        \n",
    "    def build_tree(self, X_train, y_train, height):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_train (ndarray): [n_samples x n_features] ndarray of training data   \n",
    "            y_train (ndarray): [n_samples] ndarray of data\n",
    "            \n",
    "        \"\"\"\n",
    "        node = TreeNode()\n",
    "        # your logic here\n",
    "        if height == self.depth or self.gini_index(y_train) == 0:\n",
    "            node.isLeaf = True\n",
    "            node.label = self.majority(y_train)\n",
    "            node.left = node.right = None\n",
    "        else:\n",
    "            splitting_vector = self.find_best_split(X_train, y_train)\n",
    "            split_masks = np.transpose(np.matmul(X_train, np.transpose(splitting_vector)))\n",
    "            split_masks = np.array(split_masks) > 0\n",
    "            if len(y_train[~split_masks]) == 0 or len(y_train[split_masks]) == 0:\n",
    "                node.isLeaf = True\n",
    "                node.label = self.majority(y_train)\n",
    "                node.left = node.right = None\n",
    "            else:\n",
    "                node.split_vector = splitting_vector\n",
    "                node.left = self.build_tree(X_train[~split_masks], y_train[~split_masks], height+1)\n",
    "                node.right = self.build_tree(X_train[split_masks], y_train[split_masks], height+1)            \n",
    "        return node\n",
    "    \n",
    "    def find_best_split(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_train (ndarray): [n_samples x n_features] ndarray of training data   \n",
    "            y_train (ndarray): [n_samples] ndarray of data\n",
    "            np.array([np.random.normal(mu, sigma, len(data.X_train[0])) for i in range(0, self.candidate_splits)])\n",
    "        \"\"\"\n",
    "        mu, sigma = 0, 1.0 # mean and standard deviation\n",
    "        candidate_split_vectors = np.array([np.random.normal(mu, sigma, len(data.X_train[0])) for i in range(0, self.candidate_splits)])\n",
    "        solution = np.matmul(X_train, np.transpose(candidate_split_vectors))\n",
    "        solution_mask = np.transpose(solution) > 0\n",
    "        ginis = np.array([2*self.gini_index(y_train)-self.gini_index(y_train[~solution_mask[i]])*len(y_train[~solution_mask[i]])/len(y_train)-self.gini_index(y_train[solution_mask[i]])*len(y_train[solution_mask[i]])/len(y_train) for i in range(0, self.candidate_splits)])\n",
    "        return candidate_split_vectors[np.argmax(ginis)]\n",
    "            \n",
    "        \n",
    "    def gini_index(self, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            y (ndarray): [n_samples] ndarray of data\n",
    "        \"\"\"\n",
    "        classes, count = np.unique(y, return_counts = True)\n",
    "        count = count/len(y)\n",
    "        classes_count_dict = dict(zip(classes, count))\n",
    "        if 1 not in classes:\n",
    "            classes_count_dict[1] = 0.0\n",
    "        if -1 not in classes:\n",
    "            classes_count_dict[-1] = 0.0\n",
    "        return classes_count_dict[-1]*classes_count_dict[1]\n",
    "\n",
    "    \n",
    "    def majority(self, y):\n",
    "        \"\"\"\n",
    "        Return the major class in ndarray y\n",
    "        \"\"\"\n",
    "        (values, counts) = np.unique(y,return_counts=True)\n",
    "        ind = np.argmax(counts)\n",
    "        return values[ind]\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        BaggingClassifier prediction for new data points in X\n",
    "        \n",
    "        Args:\n",
    "            X (ndarray): [n_samples x n_features] ndarray of data \n",
    "            \n",
    "        Returns:\n",
    "            yhat (ndarray): [n_samples] ndarray of predicted labels {-1,1}\n",
    "        \"\"\"\n",
    "        y_hat = []\n",
    "        for xx in X:\n",
    "            node = self.root\n",
    "            while node.isLeaf is False:\n",
    "                dot_product = np.dot(node.split_vector, xx)\n",
    "                if dot_product > 0:\n",
    "                    node = node.right\n",
    "                else:\n",
    "                    node = node.left\n",
    "            y_hat.append(node.getLabel())\n",
    "        return y_hat\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomDecisionTree for Handwritten Digit Recognition\n",
    "\n",
    "After you've successfully completed `RandomDecisionTree`, and train using the default values in the constructor and report accuracy on the test set. Use the data from `ThreesAndEights` class initialized variable `data` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the test set is :  0.902893575282001  or  90.2893575282001 %\n"
     ]
    }
   ],
   "source": [
    "# Please wait for 10 to 12 seconds for the program to run\n",
    "tree = RandomDecisionTree()\n",
    "tree = tree.fit(data.X_train, data.y_train)\n",
    "outputs = tree.predict(data.X_valid)\n",
    "matches = 0\n",
    "for i in range(len(outputs)):\n",
    "    if outputs[i] == data.y_valid[i]:\n",
    "        matches= matches + 1\n",
    "print('The accuracy of the test set is : ', matches/len(outputs), ' or ', 100*matches/len(outputs),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest [5-points]\n",
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "\n",
    "Random forest trains random decision trees on bootstrapped training points. Thus, you can implementation of methods (`bootstrap`, `predict`) from `BaggingClassifier` class directly. Only difference being, you have to use the `RandomDecisionTree` as base which you implemented previously instead of sklearn's implementation of `DecisionTreeClassifier`). Implement the `fit` method in the class below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest(BaggingClassifier):\n",
    "    def __init__(self, ratio = 0.20, N = 20, max_depth = 10, candidate_splits = 100):\n",
    "        self.ratio = ratio\n",
    "        self.N = N\n",
    "        self.learners = []\n",
    "        self.candidate_splits = candidate_splits\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train Bagging Ensemble Classifier on data\n",
    "        \n",
    "        Args:\n",
    "            X_train (ndarray): [n_samples x n_features] ndarray of training data   \n",
    "            y_train (ndarray): [n_samples] ndarray of data \n",
    "        \"\"\"\n",
    "        for i in range(self.N):\n",
    "            b_X, b_y = self.boostrap(X_train, y_train)\n",
    "            model_clone = RandomDecisionTree(candidate_splits = self.candidate_splits, depth = self.max_depth)\n",
    "            model_clone.fit(b_X, b_y)\n",
    "            self.learners.append(model_clone)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest for Handwritten Digit Recognition [5-points]\n",
    "***\n",
    "\n",
    "After you've successfully completed `RandomForest` find the optimal values of `ratio`, `N`, `candidate_splits` and `depth` using k-fold cross validation on. Feel free to use sklearn library to split your training data. Use the data from `ThreesAndEights` class intialized variable `data`. \n",
    "\n",
    "Justify why those values are optimal.\n",
    "\n",
    "Report best accuracy on the testing data using those optimal parameter values.\n",
    "\n",
    "> The optimal values for the random forest classifier are achieved at `ratio = 0.4`, `N = 40`, `max_depth = 10` and `candidate splits = 400`. As we see in the graphs below we shall see that the maxima of the accuracy is at the above values after which the accuracy shows a decreasing trend due to increasing overfitting due to excessively effort for seperating the data well in training which introduces errors in training. The accuracy for these values is found to be approximately, $97\\%$. The values above may vary slightly due to randomization in the algorithm of selecting data and splitting vector or hyperplane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code may take apprroximately an hour to compute . Please be patient.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(3)\n",
    "kf.get_n_splits(data.X_train)\n",
    "\n",
    "range_ratio = np.arange(0.1, 0.5, 0.1)\n",
    "accuracies_ratio = []\n",
    "for r in range_ratio:\n",
    "    cv_accuracies = []\n",
    "    for indices_train, indices_test in kf.split(data.X_train):\n",
    "        classifier = RandomForest(ratio = r)\n",
    "        classifier.fit(data.X_train[indices_train], data.y_train[indices_train])\n",
    "        outputs = classifier.predict(data.X_train[indices_test])\n",
    "        matches = 0\n",
    "        test_y = data.y_train[indices_test]\n",
    "        for i in range(len(outputs)):\n",
    "            if outputs[i] == test_y[i]:\n",
    "                matches= matches + 1\n",
    "        cv_accuracies.append(matches/len(outputs))\n",
    "    accuracies_ratio.append(sum(cv_accuracies)/len(cv_accuracies))\n",
    "    print('Computed the accuracy for ratio : ', r)\n",
    "print(\"The optimal value of the ratio is:\", range_ratio[np.argmax(accuracies_ratio)])\n",
    "    \n",
    "accuracies_N = []\n",
    "N_range = np.arange(10,60,10)\n",
    "for n in N_range:\n",
    "    cv_accuracies = []\n",
    "    for indices_train, indices_test in kf.split(data.X_train):\n",
    "        classifier = RandomForest(N = n)\n",
    "        classifier.fit(data.X_train[indices_train], data.y_train[indices_train])\n",
    "        outputs = classifier.predict(data.X_train[indices_test])\n",
    "        matches = 0\n",
    "        test_y = data.y_train[indices_test]\n",
    "        for i in range(len(outputs)):\n",
    "            if outputs[i] == test_y[i]:\n",
    "                matches= matches + 1\n",
    "        cv_accuracies.append(matches/len(outputs))\n",
    "    accuracies_N.append(sum(cv_accuracies)/len(cv_accuracies))\n",
    "    print(\"Computed the accuracy for N : \", n)\n",
    "print(\"The optimal value of the N is : \", N_range[np.argmax(accuracies_N)])\n",
    "    \n",
    "accuracies_depth = []\n",
    "depth_range = range(2,11,2)\n",
    "for d in depth_range:\n",
    "    cv_accuracies = []\n",
    "    for indices_train, indices_test in kf.split(data.X_train):\n",
    "        classifier = RandomForest(max_depth = d)\n",
    "        classifier.fit(data.X_train[indices_train], data.y_train[indices_train])\n",
    "        outputs = classifier.predict(data.X_train[indices_test])\n",
    "        matches = 0\n",
    "        test_y = data.y_train[indices_test]\n",
    "        for i in range(len(outputs)):\n",
    "            if outputs[i] == test_y[i]:\n",
    "                matches= matches + 1\n",
    "        cv_accuracies.append(matches/len(outputs))\n",
    "    accuracies_depth.append(sum(cv_accuracies)/len(cv_accuracies))\n",
    "    print(\"Computed the accuracy for the d : \",d)\n",
    "print(\"The optimal value of the Depth is : \", depth_range[np.argmax(accuracies_depth)])\n",
    "\n",
    "accuracies_splits = []\n",
    "split_range = range(100,500, 100)\n",
    "for s in split_range:\n",
    "    cv_accuracies = []\n",
    "    for indices_train, indices_test in kf.split(data.X_train):\n",
    "        classifier = RandomForest(candidate_splits = s)\n",
    "        classifier.fit(data.X_train[indices_train], data.y_train[indices_train])\n",
    "        outputs = classifier.predict(data.X_train[indices_test])\n",
    "        matches = 0\n",
    "        test_y = data.y_train[indices_test]\n",
    "        for i in range(len(outputs)):\n",
    "            if outputs[i] == test_y[i]:\n",
    "                matches= matches + 1\n",
    "        cv_accuracies.append(matches/len(outputs))\n",
    "    accuracies_splits.append(sum(cv_accuracies)/len(cv_accuracies))\n",
    "    print(\"Computed the accuracy for the Candidate splits : \", s)\n",
    "print(\"The optimal value of the candidate splits is : \", split_range[np.argmax(accuracies_splits)])\n",
    "\n",
    "plt.plot(list(range_ratio), accuracies_ratio)\n",
    "plt.xlabel('ratio')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "plt.plot(list(N_range), accuracies_N)\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()    \n",
    "plt.plot(list(depth_range), accuracies_depth)\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "plt.plot(list(split_range), accuracies_splits)\n",
    "plt.xlabel('candidate splits')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "forest = RandomForest(candidate_splits = 400,\n",
    "                     N = 40,\n",
    "                     max_depth = 10,\n",
    "                     ratio = 0.4) \n",
    "\n",
    "forest.fit(data.X_train, data.y_train)\n",
    "print('trained!')\n",
    "outputs = forest.predict(data.X_valid)\n",
    "matches = 0\n",
    "for i in range(len(outputs)):\n",
    "    if outputs[i] == data.y_valid[i]:\n",
    "        matches= matches + 1\n",
    "print('The accuracy of the test set is : ', matches/len(outputs), ' or ', 100*matches/len(outputs),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
